{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([759, 8])\n",
      "torch.Size([759, 1])\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('data-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = Variable(torch.from_numpy(xy[:,0:-1]))\n",
    "y_data = Variable(torch.from_numpy(xy[:,[-1]]))\n",
    "\n",
    "print(x_data.data.shape)\n",
    "print(y_data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 6)\n",
    "        self.l2 = torch.nn.Linear(6, 4)\n",
    "        self.l3 = torch.nn.Linear(4, 1)\n",
    "        \n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "#         self.activation = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.activation(self.l1(x))\n",
    "        out2 = self.activation(self.l2(out1))\n",
    "        y_pred = self.activation(self.l3(out2))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.66207355260849\n",
      "1 0.6605484485626221\n",
      "2 0.6591643691062927\n",
      "3 0.6579077839851379\n",
      "4 0.6567668318748474\n",
      "5 0.6557304263114929\n",
      "6 0.6547895669937134\n",
      "7 0.6539340615272522\n",
      "8 0.6531571745872498\n",
      "9 0.6524511575698853\n",
      "10 0.6518085598945618\n",
      "11 0.6512252688407898\n",
      "12 0.650693953037262\n",
      "13 0.6502114534378052\n",
      "14 0.6497716307640076\n",
      "15 0.6493722200393677\n",
      "16 0.6490082144737244\n",
      "17 0.6486773490905762\n",
      "18 0.6483761072158813\n",
      "19 0.6481011509895325\n",
      "20 0.6478510499000549\n",
      "21 0.6476238369941711\n",
      "22 0.6474161744117737\n",
      "23 0.64722740650177\n",
      "24 0.6470553874969482\n",
      "25 0.6468988060951233\n",
      "26 0.6467553377151489\n",
      "27 0.6466255187988281\n",
      "28 0.6465061902999878\n",
      "29 0.6463980674743652\n",
      "30 0.6462996602058411\n",
      "31 0.6462092995643616\n",
      "32 0.6461277604103088\n",
      "33 0.6460528373718262\n",
      "34 0.645984411239624\n",
      "35 0.6459219455718994\n",
      "36 0.6458652019500732\n",
      "37 0.6458134055137634\n",
      "38 0.645765483379364\n",
      "39 0.6457228064537048\n",
      "40 0.6456835865974426\n",
      "41 0.6456473469734192\n",
      "42 0.6456144452095032\n",
      "43 0.6455843448638916\n",
      "44 0.6455574035644531\n",
      "45 0.6455328464508057\n",
      "46 0.6455092430114746\n",
      "47 0.6454885005950928\n",
      "48 0.6454695463180542\n",
      "49 0.6454524993896484\n",
      "50 0.6454362273216248\n",
      "51 0.6454213857650757\n",
      "52 0.6454084515571594\n",
      "53 0.6453961730003357\n",
      "54 0.6453849673271179\n",
      "55 0.6453751921653748\n",
      "56 0.6453655958175659\n",
      "57 0.6453571319580078\n",
      "58 0.6453490853309631\n",
      "59 0.6453427076339722\n",
      "60 0.6453360319137573\n",
      "61 0.6453300714492798\n",
      "62 0.6453246474266052\n",
      "63 0.6453194618225098\n",
      "64 0.6453151106834412\n",
      "65 0.6453105807304382\n",
      "66 0.6453069448471069\n",
      "67 0.6453035473823547\n",
      "68 0.6453003287315369\n",
      "69 0.6452974081039429\n",
      "70 0.6452944874763489\n",
      "71 0.6452924013137817\n",
      "72 0.6452897787094116\n",
      "73 0.6452874541282654\n",
      "74 0.6452854871749878\n",
      "75 0.6452838182449341\n",
      "76 0.6452822089195251\n",
      "77 0.6452808380126953\n",
      "78 0.645279586315155\n",
      "79 0.6452782154083252\n",
      "80 0.6452763080596924\n",
      "81 0.6452757120132446\n",
      "82 0.6452745199203491\n",
      "83 0.6452736854553223\n",
      "84 0.6452730298042297\n",
      "85 0.6452720761299133\n",
      "86 0.6452710628509521\n",
      "87 0.6452704668045044\n",
      "88 0.6452701687812805\n",
      "89 0.6452687978744507\n",
      "90 0.6452683806419373\n",
      "91 0.6452678442001343\n",
      "92 0.6452673673629761\n",
      "93 0.6452669501304626\n",
      "94 0.6452661752700806\n",
      "95 0.6452658176422119\n",
      "96 0.6452652812004089\n",
      "97 0.645265519618988\n",
      "98 0.6452651023864746\n",
      "99 0.6452642679214478\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.data[0])#, y_pred[:5], y_data[:5])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
